{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "octisCTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "code adapted from https://github.com/MIND-Lab/OCTIS"
      ],
      "metadata": {
        "id": "4UwTLYt9Ivnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install octis"
      ],
      "metadata": {
        "id": "-eBwuTobtHgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "sbTcnvR0yVwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p57dps6tslyR"
      },
      "outputs": [],
      "source": [
        "from octis.dataset.dataset import Dataset\n",
        "from octis.models.CTM import CTM\n",
        "dataset = Dataset()\n",
        "dataset.load_custom_dataset_from_folder(\"/content/gdrive/My Drive/AllComments/SanJose\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
        "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
        "# eval a model\n",
        "def eval_model(model_output, num_topics):\n",
        "    metric = TopicDiversity(topk=10) # Initialize metric\n",
        "    topic_diversity_score = metric.score(model_output) # Compute score of the metric\n",
        "    print(\"Topic diversity \", i , \":\", str(topic_diversity_score))\n",
        "\n",
        "    npmi = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_npmi')\n",
        "    npmi_score = npmi.score(model_output)\n",
        "    print(\"Coherence \" , i , \":\", str(npmi_score))"
      ],
      "metadata": {
        "id": "X5E0SD8ohHz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train a model\n",
        "#for i in range(2, 51):\n",
        "#  model = CTM(num_topics=i)  # Create model\n",
        "#  model_output = model.train_model(dataset) # Train the model\n",
        "#  eval_model(model_output, i)\n"
      ],
      "metadata": {
        "id": "YjTQ-eDzs1NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CTM() #num_topics=24) #num_topics=16)  # Create model\n",
        "model_output = model.train_model(dataset) # Train the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "kfaLk80vYosv",
        "outputId": "1e78f1e3-1820-430b-d479-7e6c84d89006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-193734bafa5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#num_topics=24) #num_topics=16)  # Create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/octis/models/CTM.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, dataset, hyperparameters, top_words)\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mbert_test_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bert_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_test.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mbert_val_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bert_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_val.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 bert_model=self.hyperparameters[\"bert_model\"])\n\u001b[0m\u001b[1;32m    101\u001b[0m             self.model = ctm.CTM(input_size=input_size, bert_input_size=x_train.X_bert.shape[1], model_type='prodLDA',\n\u001b[1;32m    102\u001b[0m                                  \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_topics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dropout'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/octis/models/CTM.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(vocab, train, bert_model, test, validation, bert_train_path, bert_test_path, bert_val_path)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mb_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_bert_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_train_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCTMDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/octis/models/contextualized_topic_models/datasets/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, X_bert, idx2token)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \"\"\"\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             raise Exception(\"Wait! BoW and Contextual Embeddings have different sizes! \"\n\u001b[0m\u001b[1;32m     18\u001b[0m                             \"You might want to check if the BoW preparation method has removed some documents. \")\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Wait! BoW and Contextual Embeddings have different sizes! You might want to check if the BoW preparation method has removed some documents. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eval a model\n",
        "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
        "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
        "\n",
        "metric = TopicDiversity(topk=10) # Initialize metric\n",
        "topic_diversity_score = metric.score(model_output) # Compute score of the metric\n",
        "print(\"Topic diversity: \"+str(topic_diversity_score))\n",
        "\n",
        "npmi = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_npmi')\n",
        "npmi_score = npmi.score(model_output)\n",
        "print(\"Coherence: \"+str(npmi_score))"
      ],
      "metadata": {
        "id": "MzYLA-vrsoqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for topic in model_output['topics']:\n",
        "  print(topic)"
      ],
      "metadata": {
        "id": "8GH7fe6KcUQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from octis.optimization.optimizer import Optimizer\n",
        "#from skopt.space.space import Real\n",
        "\n",
        "# Define the search space. To see which hyperparameters to optimize, see the topic model's initialization signature\n",
        "#search_space = {\"alpha\": Real(low=0.001, high=5.0), \"eta\": Real(low=0.001, high=5.0)}\n",
        "\n",
        "# Initialize an optimizer object and start the optimization.\n",
        "##optimizer=Optimizer()\n",
        "#optResult=optimizer.optimize(model, dataset, TopicDiversity(), search_space, save_path=\"../results\", # path to store the results\n",
        "##                             number_of_call=30, # number of optimization iterations\n",
        "#                             model_runs=5) # number of runs of the topic model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AKn0CfrAgPvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#optResult.save_to_csv(\"results.csv\")\n",
        "#files.download(\"results.csv\")"
      ],
      "metadata": {
        "id": "1slruKiRhlLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}